{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用于cifar10图像分类的5层卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.导入模块,数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# 导入模块\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"    #解决输出警告from ._conv import register_converters as _register_converters\n",
    "os.chdir('/home/david/tensorflow/卷积神经网络/cifar10')     #切换到cifar10目录\n",
    "import cifar10, cifar10_input\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 80\r\n",
      "-rwxrwxrwx 1 david david  1683 4月   4 14:08 BUILD\r\n",
      "drwxr-xr-x 2 david david  4096 6月   5  2009 cifar-10-batches-bin\r\n",
      "-rwxrwxrwx 1 david david  5458 4月   4 14:08 cifar10_eval.py\r\n",
      "-rwxrwxrwx 1 david david 10209 4月   4 14:08 cifar10_input.py\r\n",
      "-rwxrwxrwx 1 david david  2274 4月   4 14:08 cifar10_input_test.py\r\n",
      "-rwxrwxrwx 1 david david 10648 4月   4 14:08 cifar10_multi_gpu_train.py\r\n",
      "-rwxrwxrwx 1 david david 14675 4月   4 14:08 cifar10.py\r\n",
      "-rwxrwxrwx 1 david david  4491 4月   4 14:08 cifar10_train.py\r\n",
      "-rwxrwxrwx 1 david david   899 4月   4 14:08 __init__.py\r\n",
      "drwxrwxr-x 2 david david  4096 4月   5 22:16 __pycache__\r\n",
      "-rwxrwxrwx 1 david david   624 4月   4 14:08 README.md\r\n"
     ]
    }
   ],
   "source": [
    "# 下载数据集(已下载)\n",
    "# cifar10.maybe_download_and_extract() # 下载的位置为`/tmp/cifar10_data/cifar-10-batches-bin`\n",
    "!ls -l # cifar-10-batches-bin 是存放cifar10数据的文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n"
     ]
    }
   ],
   "source": [
    "# 数据预处理\n",
    "max_steps = 3000\n",
    "batch_size = 128\n",
    "data_dir = './cifar-10-batches-bin'\n",
    "# 获得数据增强,增广的训练集(左右翻转,随机裁剪,随机对比度,随机亮度及数据标准化)\n",
    "images_train, labels_train = cifar10_input.distorted_inputs(data_dir=data_dir, batch_size=batch_size)\n",
    "# 测试集只裁剪中间的24*24,并数据标准化处理\n",
    "images_test, labels_test = cifar10_input.inputs(eval_data=True, data_dir=data_dir, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.定义权重初始化函数及训练集数据占位符变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义输入数据及其标签\n",
    "image_holder = tf.placeholder(tf.float32, [batch_size, 24, 24, 3])   # 输入的图像\n",
    "label_holder = tf.placeholder(tf.float32, [batch_size])              # 标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 权重初始化函数\n",
    "def variable_with_weight_loss(shape, stddev, w1):\n",
    "    \"\"\"\n",
    "    功能: 为权重进行初始化,并给权重添加一定的损失\n",
    "    参数: shape:权重向量的形状;stddev:标准差的大小;w1:控制权重的损失大小\n",
    "    返回: 初始化的权重向量\n",
    "    \"\"\"\n",
    "    var = tf.Variable(tf.truncated_normal(shape, stddev=stddev))   # 用截断的正态分布初始化权重\n",
    "    if w1 is not None:  # 如果为权重添加l2损失\n",
    "        weight_loss = tf.multiply(tf.nn.l2_loss(var), w1, name='weight_loss')\n",
    "        tf.add_to_collection('losses', weight_loss)          # 将weight loss添加到总的loss中\n",
    "    return var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.定义网络的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一层卷积层[5,5,3,64]\n",
    "kernel1 = variable_with_weight_loss([5, 5, 3, 64], stddev=5e-2, w1=0.0)   # 不计算weight的loss\n",
    "conv_kernel1 = tf.nn.conv2d(image_holder, kernel1, [1, 1, 1, 1], padding='SAME')\n",
    "bias1 = tf.Variable(tf.constant(0.0, shape=[64]))\n",
    "conv1 = tf.nn.relu(conv_kernel1 + bias1)                                              # tf.nn.bias_add()功能类似,卷积           \n",
    "pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME') # 最大池化\n",
    "norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001/9.0, beta=0.75)         # lrn局部响应均值化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二层卷积层[5,5,64,64]\n",
    "kernel2 = variable_with_weight_loss([5, 5, 64, 64], stddev=5e-2, w1=0.0)\n",
    "conv_kernel2 = tf.nn.conv2d(norm1, kernel2, [1, 1, 1, 1], padding='SAME')\n",
    "bias2 = tf.Variable(tf.constant(0.0, shape=[64]))\n",
    "conv2 = tf.nn.relu(conv_kernel2 + bias2)\n",
    "norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001/9.0, beta=0.75)\n",
    "pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第三层全连接层[384]\n",
    "pool2_flat = tf.reshape(pool2, [batch_size, -1])   # 将feature map重塑成一个一维度向量\n",
    "dim = pool2_flat.get_shape()[1].value              # 获取向量的维度\n",
    "weight3 = variable_with_weight_loss([dim, 384], stddev=0.04, w1=0.004)  # 全连接层的权重,加入损失\n",
    "bias3 = tf.Variable(tf.constant(0.0, shape=[384])) # 偏置项\n",
    "fc3 = tf.nn.relu(tf.matmul(pool2_flat, weight3) + bias3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第四层全连接层 [192]\n",
    "weight4 = variable_with_weight_loss([384, 192], stddev=0.04, w1=0.04)   # 全连接层的权重,加入损失\n",
    "bias4 = tf.Variable(tf.constant(0.0, shape=[192]))\n",
    "fc4 = tf.nn.relu(tf.matmul(fc3, weight4) + bias4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第五层全连接层==>分类层,概率层\n",
    "weight5 = variable_with_weight_loss([192, 10], stddev=1/192.0, w1=0.0) # 标准差为节点的倒数\n",
    "bias5 = tf.Variable(tf.constant(0.0, shape=[10]))\n",
    "logits = tf.matmul(fc4, weight5) + bias5                               # 不需要relu非线性激活"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.定义损失函数,准确率函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
